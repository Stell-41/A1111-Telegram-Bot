# bot/handlers/user_handlers.py
import asyncio
from typing import Union
from aiogram import Router, F, types
from aiogram.filters import CommandStart, Command
from aiogram.fsm.context import FSMContext
from aiogram.types import BufferedInputFile

import config
from bot.states import GenerateFlow
# --- –ö–õ–ê–í–ò–ê–¢–£–†–´: –°–¢–ê–†–ê–Ø get_character_keyboard –£–î–ê–õ–ï–ù–ê ---
from bot.keyboards import (
    get_generation_keyboard, get_settings_keyboard, get_sampler_keyboard,
    get_model_selection_keyboard, get_post_generation_keyboard,
    get_saved_prompts_keyboard, get_delete_prompts_keyboard, get_character_selection_keyboard
)
# --- –õ–û–ì–ò–ö–ê: –ò–°–ü–û–õ–¨–ó–£–ï–¢–°–Ø –ù–û–í–ê–Ø –§–£–ù–ö–¶–ò–Ø –î–õ–Ø –ù–ï–°–ö–û–õ–¨–ö–ò–• –ü–ï–†–°–û–ù–ê–ñ–ï–ô ---
from services.prompt_logic import generate_prompts_for_characters
from services.a1111_api_service import generate_image, get_available_models
from services.user_data_service import (
    get_user_data, save_user_data, add_saved_prompt, remove_saved_prompt, MAX_SAVED_PROMPTS
)
from bot.middleware import load_settings

router = Router()

def format_prompt_message(prompts: list, index: int) -> str:
    positive, negative = prompts[index]
    return (
        f"**–í–∞—Ä–∏–∞–Ω—Ç {index + 1}/{len(prompts)}**\n\n"
        f"‚úÖ **Prompt:**\n`{positive}`\n\n"
        f"‚ùå **Negative Prompt:**\n`{negative}`"
    )

@router.message(CommandStart())
async def cmd_start(message: types.Message):
    await message.answer(
        "–ü—Ä–∏–≤–µ—Ç! üëã –Ø –±–æ—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–º—Ç–æ–≤ –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ A1111.\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É /generate, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å."
    )

# --- –û–ë–ù–û–í–õ–ï–ù–ù–´–ô –°–¶–ï–ù–ê–†–ò–ô –ì–ï–ù–ï–†–ê–¶–ò–ò (–ï–î–ò–ù–°–¢–í–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø) ---

@router.message(Command("generate"))
async def cmd_generate(message: types.Message, state: FSMContext):
    await state.clear()
    await state.set_state(GenerateFlow.choosing_character)
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
    await state.update_data(selected_characters=[])
    await message.answer(
        "–í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π:",
        reply_markup=get_character_selection_keyboard()
    )

# –≠—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ "–ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç" –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π –≤ —Å–ø–∏—Å–∫–µ
@router.callback_query(GenerateFlow.choosing_character, F.data.startswith("toggle_char_"))
async def toggle_character(callback: types.CallbackQuery, state: FSMContext):
    character_id = callback.data.removeprefix("toggle_char_")
    
    user_data = await state.get_data()
    selected = user_data.get("selected_characters", [])
    
    if character_id in selected:
        selected.remove(character_id)
    else:
        selected.append(character_id)
        
    await state.update_data(selected_characters=selected)
    
    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É, –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—è –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    await callback.message.edit_reply_markup(
        reply_markup=get_character_selection_keyboard(selected)
    )
    await callback.answer()

# –≠—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –Ω–∞ –∫–Ω–æ–ø–∫—É "–ì–æ—Ç–æ–≤–æ"
@router.callback_query(GenerateFlow.choosing_character, F.data == "chars_done")
async def characters_selected(callback: types.CallbackQuery, state: FSMContext):
    user_data = await state.get_data()
    if not user_data.get("selected_characters"):
        await callback.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞.", show_alert=True)
        return

    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
    user_id = callback.from_user.id
    user_settings = get_user_data(user_id)["settings"]
    await state.update_data(settings=user_settings)
    
    await state.set_state(GenerateFlow.settings_menu)
    await callback.message.edit_text(
        "–ü–µ—Ä—Å–æ–Ω–∞–∂–∏ –≤—ã–±—Ä–∞–Ω—ã. –¢–µ–ø–µ—Ä—å –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.",
        reply_markup=get_settings_keyboard(user_settings)
    )
    await callback.answer()

# --- –õ–û–ì–ò–ö–ê –£–ü–†–ê–í–õ–ï–ù–ò–Ø –ù–ê–°–¢–†–û–ô–ö–ê–ú–ò –ò –ü–†–û–ú–¢–ê–ú–ò ---

@router.callback_query(GenerateFlow.settings_menu, F.data == "settings_done")
async def settings_done(callback: types.CallbackQuery, state: FSMContext):
    user_data = await state.get_data()
    if not user_data.get("settings", {}).get("model_name"):
        await callback.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å.", show_alert=True)
        return

    await state.set_state(GenerateFlow.waiting_for_base_prompt)
    await callback.message.edit_text(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º—Ç –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π:",
        reply_markup=get_saved_prompts_keyboard(callback.from_user.id)
    )
    await callback.answer()

@router.callback_query(GenerateFlow.settings_menu, F.data.startswith("edit_setting_"))
async def edit_setting(callback: types.CallbackQuery, state: FSMContext):
    setting_key = callback.data.removeprefix("edit_setting_")

    if setting_key == "model_name":
        await callback.message.edit_text("–ó–∞–≥—Ä—É–∂–∞—é —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –∏–∑ A1111...")
        models = get_available_models()
        if not models:
            await callback.answer("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ A1111 –∑–∞–ø—É—â–µ–Ω.", show_alert=True)
            user_data = await state.get_data()
            await callback.message.edit_text(
                "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –û–Ω–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –¥–ª—è –≤–∞—à–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è.",
                reply_markup=get_settings_keyboard(user_data["settings"])
            )
            return
        aliases = load_settings().get("model_aliases", {})
        await callback.message.edit_text(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏:",
            reply_markup=get_model_selection_keyboard(models, aliases)
        )
        await callback.answer()
        return

    if setting_key == "sampler_name":
        await callback.message.edit_text(
            "–í—ã–±–µ—Ä–∏—Ç–µ —Å–µ–º–ø–ª–µ—Ä –∏–∑ —Å–ø–∏—Å–∫–∞:",
            reply_markup=get_sampler_keyboard()
        )
        await callback.answer()
        return

    await state.update_data(editing_setting=setting_key)
    await state.set_state(GenerateFlow.waiting_for_setting_value)
    
    message_text = f"–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è `{setting_key}`:"
    if setting_key == 'cfg_scale':
        tooltip = (
            "\n\n*–ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ CFG Scale:*\n"
            "‚Ä¢ *–ù–∏–∑–∫–æ–µ (2-6):* –±–æ–ª—å—à–µ –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏.\n"
            "‚Ä¢ *–°—Ä–µ–¥–Ω–µ–µ (7-10):* —Ö–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å.\n"
            "‚Ä¢ *–í—ã—Å–æ–∫–æ–µ (11+):* —Å—Ç—Ä–æ–≥–æ–µ —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–º—Ç—É."
        )
        message_text += tooltip
        
    await callback.message.edit_text(message_text, parse_mode="Markdown")
    await callback.answer()


@router.callback_query(GenerateFlow.settings_menu, F.data.startswith("set_model_"))
async def select_model(callback: types.CallbackQuery, state: FSMContext):
    model_name = callback.data.removeprefix("set_model_")
    user_data_state = await state.get_data()
    settings = user_data_state.get("settings")
    settings["model_name"] = model_name
    
    user_data_db = get_user_data(callback.from_user.id)
    user_data_db["settings"] = settings
    save_user_data(callback.from_user.id, user_data_db)

    await state.update_data(settings=settings)
    await callback.message.edit_text(
        "–ú–æ–¥–µ–ª—å –≤—ã–±—Ä–∞–Ω–∞. –ú–æ–∂–µ—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —á—Ç–æ-—Ç–æ –µ—â–µ –∏–ª–∏ –Ω–∞–∂–∞—Ç—å '–ì–æ—Ç–æ–≤–æ'.",
        reply_markup=get_settings_keyboard(settings)
    )
    await callback.answer()

@router.callback_query(GenerateFlow.settings_menu, F.data.startswith("set_sampler_"))
async def select_sampler(callback: types.CallbackQuery, state: FSMContext):
    sampler_name = callback.data.removeprefix("set_sampler_")
    user_data_state = await state.get_data()
    settings = user_data_state.get("settings")
    settings["sampler_name"] = sampler_name
    
    user_data_db = get_user_data(callback.from_user.id)
    user_data_db["settings"] = settings
    save_user_data(callback.from_user.id, user_data_db)

    await state.update_data(settings=settings)
    await callback.message.edit_text(
        "–°–µ–º–ø–ª–µ—Ä –æ–±–Ω–æ–≤–ª–µ–Ω. –ú–æ–∂–µ—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å —á—Ç–æ-—Ç–æ –µ—â–µ –∏–ª–∏ –Ω–∞–∂–∞—Ç—å '–ì–æ—Ç–æ–≤–æ'.",
        reply_markup=get_settings_keyboard(settings)
    )
    await callback.answer()

@router.callback_query(GenerateFlow.settings_menu, F.data == "back_to_settings")
async def back_to_settings(callback: types.CallbackQuery, state: FSMContext):
    user_data = await state.get_data()
    settings = user_data["settings"]
    await callback.message.edit_text(
        "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –û–Ω–∏ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –¥–ª—è –≤–∞—à–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è.",
        reply_markup=get_settings_keyboard(settings)
    )
    await callback.answer()

@router.message(GenerateFlow.waiting_for_setting_value)
async def enter_setting_value(message: types.Message, state: FSMContext):
    user_data_state = await state.get_data()
    setting_key = user_data_state.get("editing_setting")
    new_value = message.text
    try:
        if setting_key in ["steps", "width", "height"]:
            new_value = int(new_value)
        elif setting_key == "cfg_scale":
            new_value = float(new_value)
    except ValueError:
        await message.answer("–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ.")
        return
        
    settings = user_data_state.get("settings")
    settings[setting_key] = new_value
    
    user_data_db = get_user_data(message.from_user.id)
    user_data_db["settings"] = settings
    save_user_data(message.from_user.id, user_data_db)
    
    await state.update_data(settings=settings)
    await state.set_state(GenerateFlow.settings_menu)
    await message.answer(
        "–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.",
        reply_markup=get_settings_keyboard(settings)
    )

# --- –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø-–ü–û–ú–û–©–ù–ò–ö ---
async def generate_and_show_prompts(message_or_callback: Union[types.Message, types.CallbackQuery], state: FSMContext, base_prompt: str):
    user_data = await state.get_data()
    # –ü–æ–ª—É—á–∞–µ–º –°–ü–ò–°–û–ö –ø–µ—Ä—Å–æ–Ω–∞–∂–µ–π
    character_ids = user_data["selected_characters"]
    # –í—ã–∑—ã–≤–∞–µ–º –ù–û–í–£–Æ —Ñ—É–Ω–∫—Ü–∏—é
    prompts = generate_prompts_for_characters(character_ids, base_prompt)
    
    if not prompts:
        await message_or_callback.answer("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–º—Ç—ã.")
        await state.clear()
        return

    settings = load_settings()
    user_id = message_or_callback.from_user.id
    user_limit = float('inf')
    if user_id not in config.ADMIN_IDS:
        if str(user_id) in settings.get("whitelist", {}):
            user_limit = settings.get("generation_limit_whitelist", 20)
        else:
            user_limit = settings.get("generation_limit_default", 10)
    
    if len(prompts) > user_limit:
        text = f"–ù–∞–π–¥–µ–Ω–æ {len(prompts)} –∫–æ–º–±–∏–Ω–∞—Ü–∏–π, —á—Ç–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –≤–∞—à –ª–∏–º–∏—Ç –≤ {user_limit} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
        if isinstance(message_or_callback, types.CallbackQuery):
            await message_or_callback.answer(text, show_alert=True)
        else:
            await message_or_callback.answer(text)
        return
        
    await state.update_data(prompts=prompts, current_index=0)
    await state.set_state(GenerateFlow.viewing_results)
    
    target_message = message_or_callback.message if isinstance(message_or_callback, types.CallbackQuery) else message_or_callback
    await target_message.answer(
        format_prompt_message(prompts, 0),
        parse_mode="Markdown",
        reply_markup=get_generation_keyboard(0, len(prompts))
    )

@router.callback_query(GenerateFlow.waiting_for_base_prompt, F.data.startswith("use_prompt_"))
async def use_saved_prompt(callback: types.CallbackQuery, state: FSMContext):
    prompt_index = int(callback.data.removeprefix("use_prompt_"))
    user_data_db = get_user_data(callback.from_user.id)
    saved_prompts = user_data_db.get("saved_prompts", [])
    
    if 0 <= prompt_index < len(saved_prompts):
        base_prompt = saved_prompts[prompt_index]
        await callback.message.edit_text(f"–ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–æ–º—Ç: `{base_prompt}`\n–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏...", parse_mode="Markdown")
        await generate_and_show_prompts(callback, state, base_prompt)
    else:
        await callback.answer("–û—à–∏–±–∫–∞: –ø—Ä–æ–º—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω.", show_alert=True)

@router.callback_query(GenerateFlow.waiting_for_base_prompt, F.data == "manage_prompts_new")
async def request_new_prompt(callback: types.CallbackQuery, state: FSMContext):
    await callback.message.edit_text("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º—Ç. –ï—Å–ª–∏ –æ–Ω –Ω–æ–≤—ã–π –∏ –µ—Å—Ç—å –º–µ—Å—Ç–æ, –æ–Ω –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏.")
    await callback.answer()

@router.callback_query(GenerateFlow.waiting_for_base_prompt, F.data == "manage_prompts_delete")
async def delete_prompt_menu(callback: types.CallbackQuery, state: FSMContext):
    await callback.message.edit_text(
        "–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –ø—Ä–æ–º—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å:",
        reply_markup=get_delete_prompts_keyboard(callback.from_user.id)
    )
    await callback.answer()
    
@router.callback_query(GenerateFlow.waiting_for_base_prompt, F.data.startswith("delete_prompt_"))
async def delete_prompt_action(callback: types.CallbackQuery, state: FSMContext):
    prompt_index = int(callback.data.removeprefix("delete_prompt_"))
    remove_saved_prompt(callback.from_user.id, prompt_index)
    await callback.answer("–ü—Ä–æ–º—Ç —É–¥–∞–ª–µ–Ω!", show_alert=True)
    await callback.message.edit_text(
        "–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –ø—Ä–æ–º—Ç, –∫–æ—Ç–æ—Ä—ã–π —Ö–æ—Ç–∏—Ç–µ —É–¥–∞–ª–∏—Ç—å:",
        reply_markup=get_delete_prompts_keyboard(callback.from_user.id)
    )

@router.callback_query(GenerateFlow.waiting_for_base_prompt, F.data == "back_to_prompt_menu")
async def back_to_prompt_menu(callback: types.CallbackQuery, state: FSMContext):
    await callback.message.edit_text(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º—Ç –∏–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –Ω–æ–≤—ã–π:",
        reply_markup=get_saved_prompts_keyboard(callback.from_user.id)
    )
    await callback.answer()

# --- –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –û–ë–†–ê–ë–û–¢–ß–ò–ö –í–í–û–î–ê –ë–ê–ó–û–í–û–ì–û –ü–†–û–ú–¢–ê ---
@router.message(GenerateFlow.waiting_for_base_prompt)
async def enter_base_prompt(message: types.Message, state: FSMContext):
    base_prompt = message.text.strip()
    if not base_prompt: return
    
    user_data = get_user_data(message.from_user.id)
    if base_prompt not in user_data["saved_prompts"]:
        was_added = add_saved_prompt(message.from_user.id, base_prompt)
        if was_added:
            await message.answer("üìù –ù–æ–≤—ã–π –ø—Ä–æ–º—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
        elif len(user_data["saved_prompts"]) >= MAX_SAVED_PROMPTS:
            await message.answer(f"‚ö†Ô∏è –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –≤ {MAX_SAVED_PROMPTS} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –ø—Ä–æ–º—Ç–æ–≤. –≠—Ç–æ—Ç –ø—Ä–æ–º—Ç –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω, –Ω–æ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω.")
    
    await generate_and_show_prompts(message, state, base_prompt)

# --- –ü–†–û–°–ú–û–¢–† –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ---
@router.callback_query(GenerateFlow.viewing_results, F.data.startswith("nav_"))
async def navigate_prompts(callback: types.CallbackQuery, state: FSMContext):
    new_index = int(callback.data.split("_")[1])
    await state.update_data(current_index=new_index)
    user_data = await state.get_data()
    prompts = user_data["prompts"]
    await callback.message.edit_text(
        format_prompt_message(prompts, new_index),
        parse_mode="Markdown",
        reply_markup=get_generation_keyboard(new_index, len(prompts))
    )
    await callback.answer()


# --- –õ–û–ì–ò–ö–ê –ì–ï–ù–ï–†–ê–¶–ò–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô ---

async def run_generation_task(message: types.Message, state: FSMContext, prompts_to_generate: list, start_index: int):
    user_data = await state.get_data()
    settings = user_data["settings"]
    total_prompts = len(user_data["prompts"])
    
    for i, (positive, negative) in enumerate(prompts_to_generate, start=1):
        current_prompt_index = start_index + i - 1
        await state.update_data(current_index=current_prompt_index)
        
        await message.answer(f"‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i}/{len(prompts_to_generate)} (–ø—Ä–æ–º—Ç ‚Ññ{current_prompt_index + 1})...")
        image_bytes = generate_image(positive, negative, settings)
        
        if image_bytes:
            photo = BufferedInputFile(image_bytes, filename=f"img_{i}.png")
            await message.answer_photo(
                photo, 
                caption=f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i}/{len(prompts_to_generate)} –≥–æ—Ç–æ–≤–æ!",
                reply_markup=get_post_generation_keyboard(current_prompt_index, total_prompts)
            )
        else:
            await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i}/{len(prompts_to_generate)}.")
        await asyncio.sleep(1)

@router.callback_query(GenerateFlow.viewing_results, F.data.startswith("generate_img_"))
async def generate_single_image(callback: types.CallbackQuery, state: FSMContext, bot_status: str):
    if bot_status == "prompts_only":
        await callback.answer("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞.", show_alert=True)
        return

    await callback.message.edit_text("‚è≥ –í–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è...", reply_markup=None)
    
    user_data = await state.get_data()
    prompts = user_data["prompts"]
    settings = user_data["settings"]
    index = int(callback.data.split("_")[2])
    await state.update_data(current_index=index)
    positive_prompt, negative_prompt = prompts[index]

    image_bytes = generate_image(positive_prompt, negative_prompt, settings)
    await callback.message.delete()

    if image_bytes:
        photo = BufferedInputFile(image_bytes, filename="generated_image.png")
        await callback.message.answer_photo(
            photo, 
            caption=f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–º—Ç—É ‚Ññ{index + 1} –≥–æ—Ç–æ–≤–æ!",
            reply_markup=get_post_generation_keyboard(index, len(prompts))
        )
    else:
        await callback.message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –∑–∞–ø—É—â–µ–Ω –ª–∏ A1111.")
    
    await callback.answer()

@router.callback_query(GenerateFlow.viewing_results, F.data == "generate_all")
async def generate_all_images(callback: types.CallbackQuery, state: FSMContext, bot_status: str):
    if bot_status == "prompts_only":
        await callback.answer("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞.", show_alert=True)
        return
        
    await callback.message.delete()
    user_data = await state.get_data()
    prompts = user_data["prompts"]
    await callback.message.answer(f"‚úÖ –ü—Ä–∏–Ω—è—Ç–æ! –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –≤—Å–µ—Ö {len(prompts)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    asyncio.create_task(run_generation_task(callback.message, state, prompts, start_index=0))
    await callback.answer()

@router.callback_query(GenerateFlow.viewing_results, F.data == "generate_batch_start")
async def generate_batch_start(callback: types.CallbackQuery, state: FSMContext, bot_status: str):
    if bot_status == "prompts_only":
        await callback.answer("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞.", show_alert=True)
        return
    
    await state.set_state(GenerateFlow.waiting_for_batch_amount)
    await callback.message.answer("–í–≤–µ–¥–∏—Ç–µ, —Å–∫–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –Ω–∞—á–∞–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `10`):")
    await callback.answer()


# --- –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –î–õ–Ø –ö–ù–û–ü–û–ö –ü–û–°–õ–ï –ì–ï–ù–ï–†–ê–¶–ò–ò ---

@router.callback_query(F.data == "post_gen_main_menu")
async def post_gen_main_menu(callback: types.CallbackQuery, state: FSMContext):
    await callback.message.delete_reply_markup()
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
    await callback.message.answer("–í–æ–∑–≤—Ä–∞—Ç –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é...")
    await cmd_generate(callback.message, state)
    await callback.answer()

@router.callback_query(F.data == "post_gen_show_prompts")
async def post_gen_show_prompts(callback: types.CallbackQuery, state: FSMContext):
    await callback.message.delete()
    user_data = await state.get_data()
    prompts = user_data.get("prompts", [])
    index = user_data.get("current_index", 0)
    
    if not prompts:
        await callback.answer("–î–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–º—Ç–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–∞—á–Ω–∏—Ç–µ –∑–∞–Ω–æ–≤–æ.", show_alert=True)
        return
        
    await callback.message.answer(
        format_prompt_message(prompts, index),
        parse_mode="Markdown",
        reply_markup=get_generation_keyboard(index, len(prompts))
    )
    await callback.answer()

@router.callback_query(F.data == "post_gen_all_remaining")
async def post_gen_all_remaining(callback: types.CallbackQuery, state: FSMContext, bot_status: str):
    if bot_status == "prompts_only":
        await callback.answer("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞.", show_alert=True)
        return
        
    user_data = await state.get_data()
    prompts = user_data.get("prompts", [])
    current_index = user_data.get("current_index", 0)
    
    remaining_prompts = prompts[current_index + 1:]
    if not remaining_prompts:
        await callback.answer("–ë–æ–ª—å—à–µ –Ω–µ—Ç –ø—Ä–æ–º—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.", show_alert=True)
        return
        
    await callback.message.delete_reply_markup()
    await callback.message.answer(f"‚úÖ –ü—Ä–∏–Ω—è—Ç–æ! –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è {len(remaining_prompts)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    asyncio.create_task(run_generation_task(callback.message, state, remaining_prompts, start_index=current_index + 1))
    await callback.answer()

@router.callback_query(F.data == "post_gen_batch_start")
async def post_gen_batch_start(callback: types.CallbackQuery, state: FSMContext, bot_status: str):
    if bot_status == "prompts_only":
        await callback.answer("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞.", show_alert=True)
        return
        
    await state.set_state(GenerateFlow.waiting_for_batch_amount)
    await callback.message.answer("–í–≤–µ–¥–∏—Ç–µ, —Å–∫–æ–ª—å–∫–æ –ï–©–ï –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å:")
    await callback.answer()

@router.message(GenerateFlow.waiting_for_batch_amount)
async def generate_batch_finish(message: types.Message, state: FSMContext):
    if not message.text.isdigit() or int(message.text) <= 0:
        await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ —á–∏—Å–ª–æ.")
        return
    
    amount = int(message.text)
    user_data = await state.get_data()
    prompts = user_data.get("prompts", [])
    current_index = user_data.get("current_index", 0)
    
    prompts_to_generate = prompts[current_index + 1 : current_index + 1 + amount]
    
    if not prompts_to_generate:
        await message.answer("–ë–æ–ª—å—à–µ –Ω–µ—Ç –ø—Ä–æ–º—Ç–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.")
        await state.set_state(GenerateFlow.viewing_results)
        return

    await message.answer(f"‚úÖ –ü—Ä–∏–Ω—è—Ç–æ! –ù–∞—á–∏–Ω–∞—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Å–ª–µ–¥—É—é—â–∏—Ö {len(prompts_to_generate)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.")
    asyncio.create_task(run_generation_task(message, state, prompts_to_generate, start_index=current_index + 1))
    await state.set_state(GenerateFlow.viewing_results)

@router.callback_query(F.data == "ignore")
async def ignore_callback(callback: types.CallbackQuery):
    await callback.answer()